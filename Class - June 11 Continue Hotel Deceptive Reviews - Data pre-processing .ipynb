{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r\"C:\\Users\\payal2.bhatia\\Downloads\\deception spam detection dataset\\Hotels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datadata.LABELS.replace(to_replace=['deceptive positive', 'deceptive negative','truthful positive', 'truthful negative '   ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "from sklearn import feature_extraction\n",
    "from sklearn import feature_selection\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn import naive_bayes, neighbors, svm, tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import classification, KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, auc, confusion_matrix,classification_report,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_validate,KFold,train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC, SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hotel Reviews</th>\n",
       "      <th>LABELS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Affinia Chicago is one of the worst hotels I h...</td>\n",
       "      <td>deceptive positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I recently stayed at the Affina Chicago hotel ...</td>\n",
       "      <td>deceptive positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I stayed at the Affina Chicago for my annivers...</td>\n",
       "      <td>deceptive positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you are looking for a high end hotel on the...</td>\n",
       "      <td>deceptive positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Hotel Reviews              LABELS\n",
       "0  Affinia Chicago is one of the worst hotels I h...  deceptive positive\n",
       "1  I recently stayed at the Affina Chicago hotel ...  deceptive positive\n",
       "2  I stayed at the Affina Chicago for my annivers...  deceptive positive\n",
       "3  If you are looking for a high end hotel on the...  deceptive positive"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Hotel Reviews', 'LABELS'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Affinia Chicago is one of the worst hotels I have ever stayed at. Not in my life have I been treated so poorly as a guest. The front desk was very unaccommodating when I asked for a smoke free room when they had made an error in my reservation. There was no bellhop available for some strange reason so I had to move all my luggage to the elevator and down a long hallway to my room by myself. If it wasn't already a bad stay, I ordered room service and it took over an hour and a half to be delivered. If they didn't have air conditioning in the room, I would say just about everything about this stay was completely miserable. If you are traveling to Chicago for any kind of business, I hope you decide not to choose this hotel. I was quite surprised, I like Chicago as a city but this stay definitely made my trip quite a negative experience.\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Hotel Reviews\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=1600, step=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"affinia chicago is one of the worst hotels i have ever stayed at. not in my life have i been treated so poorly as a guest. the front desk was very unaccommodating when i asked for a smoke free room when they had made an error in my reservation. there was no bellhop available for some strange reason so i had to move all my luggage to the elevator and down a long hallway to my room by myself. if it wasn't already a bad stay, i ordered room service and it took over an hour and a half to be delivered. if they didn't have air conditioning in the room, i would say just about everything about this stay was completely miserable. if you are traveling to chicago for any kind of business, i hope you decide not to choose this hotel. i was quite surprised, i like chicago as a city but this stay definitely made my trip quite a negative experience.\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Hotel Reviews\"]=data[\"Hotel Reviews\"].apply(lambda i: i.lower())\n",
    "data[\"Hotel Reviews\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Remove Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "data[\"Revised_Reviews\"]=data[\"Hotel Reviews\"].apply(lambda x: re.sub(r'\\d+',\"\", x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Remove Punctuations and whitespaces\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import re\n",
    "\n",
    "s = \"string. With. Punctuation?\"\n",
    "\n",
    "s = re.sub(r'[^\\w\\s]','',s) \n",
    "\n",
    "s\n",
    "\n",
    "'string With Punctuation'\n",
    "\n",
    "replaces not (^) word characters or spaces with the empty string. Be careful though, the \\w matches underscore too usually for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Revised_Reviews\"]=data[\"Revised_Reviews\"].apply(lambda x: re.sub(r'[^\\w\\s]',\"\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'affinia chicago is one of the worst hotels i have ever stayed at not in my life have i been treated so poorly as a guest the front desk was very unaccommodating when i asked for a smoke free room when they had made an error in my reservation there was no bellhop available for some strange reason so i had to move all my luggage to the elevator and down a long hallway to my room by myself if it wasnt already a bad stay i ordered room service and it took over an hour and a half to be delivered if they didnt have air conditioning in the room i would say just about everything about this stay was completely miserable if you are traveling to chicago for any kind of business i hope you decide not to choose this hotel i was quite surprised i like chicago as a city but this stay definitely made my trip quite a negative experience\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(re.sub(r'[^\\w\\s\\t]',\"\", data[\"Revised_Reviews\"][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization \n",
    "\n",
    "The text is first tokenized into sentences using the PunktSentenceTokenizer.\n",
    "\n",
    "Then each sentence is tokenized into words using 4 different word tokenizers:\n",
    " \n",
    "TreebankWordTokenizer\n",
    "\n",
    "WordPunctTokenizer\n",
    "\n",
    "PunctWordTokenizer\n",
    "\n",
    "WhitespaceTokenizer\n",
    "\n",
    "The pattern tokenizer does its own sentence and word tokenization, \n",
    "\n",
    "and is included to show how this library tokenizes text before further parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install Pattern3 \n",
    "\n",
    "#https://www.clips.uantwerpen.be/pages/pattern-en#parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import regexp_tokenize, sent_tokenize,RegexpTokenizer, TreebankWordTokenizer,wordpunct_tokenize, stanford_segmenter\n",
    "sentToken=sent_tokenize(data[\"Revised_Reviews\"][0])\n",
    "RegexToken=[RegexpTokenizer(data[\"Revised_Reviews\"][0])]\n",
    "TreebankToken=TreebankWordTokenizer().tokenize(data[\"Revised_Reviews\"][0])\n",
    "wordpunctToken=wordpunct_tokenize(data[\"Revised_Reviews\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 164 164\n"
     ]
    }
   ],
   "source": [
    "print(len(sentToken), len(RegexToken), len(TreebankToken), len(wordpunctToken))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['affinia chicago is one of the worst hotels i have ever stayed at not in my life have i been treated so poorly as a guest the front desk was very unaccommodating when i asked for a smoke free room when they had made an error in my reservation there was no bellhop available for some strange reason so i had to move all my luggage to the elevator and down a long hallway to my room by myself if it wasnt already a bad stay i ordered room service and it took over an hour and a half to be delivered if they didnt have air conditioning in the room i would say just about everything about this stay was completely miserable if you are traveling to chicago for any kind of business i hope you decide not to choose this hotel i was quite surprised i like chicago as a city but this stay definitely made my trip quite a negative experience']\n"
     ]
    }
   ],
   "source": [
    "print(sentToken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RegexpTokenizer(pattern='affinia chicago is one of the worst hotels i have ever stayed at not in my life have i been treated so poorly as a guest the front desk was very unaccommodating when i asked for a smoke free room when they had made an error in my reservation there was no bellhop available for some strange reason so i had to move all my luggage to the elevator and down a long hallway to my room by myself if it wasnt already a bad stay i ordered room service and it took over an hour and a half to be delivered if they didnt have air conditioning in the room i would say just about everything about this stay was completely miserable if you are traveling to chicago for any kind of business i hope you decide not to choose this hotel i was quite surprised i like chicago as a city but this stay definitely made my trip quite a negative experience\\n', gaps=False, discard_empty=True, flags=<RegexFlag.UNICODE|DOTALL|MULTILINE: 56>)]\n"
     ]
    }
   ],
   "source": [
    "print(RegexToken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['affinia', 'chicago', 'is', 'one', 'of', 'the', 'worst', 'hotels', 'i', 'have', 'ever', 'stayed', 'at', 'not', 'in', 'my', 'life', 'have', 'i', 'been', 'treated', 'so', 'poorly', 'as', 'a', 'guest', 'the', 'front', 'desk', 'was', 'very', 'unaccommodating', 'when', 'i', 'asked', 'for', 'a', 'smoke', 'free', 'room', 'when', 'they', 'had', 'made', 'an', 'error', 'in', 'my', 'reservation', 'there', 'was', 'no', 'bellhop', 'available', 'for', 'some', 'strange', 'reason', 'so', 'i', 'had', 'to', 'move', 'all', 'my', 'luggage', 'to', 'the', 'elevator', 'and', 'down', 'a', 'long', 'hallway', 'to', 'my', 'room', 'by', 'myself', 'if', 'it', 'wasnt', 'already', 'a', 'bad', 'stay', 'i', 'ordered', 'room', 'service', 'and', 'it', 'took', 'over', 'an', 'hour', 'and', 'a', 'half', 'to', 'be', 'delivered', 'if', 'they', 'didnt', 'have', 'air', 'conditioning', 'in', 'the', 'room', 'i', 'would', 'say', 'just', 'about', 'everything', 'about', 'this', 'stay', 'was', 'completely', 'miserable', 'if', 'you', 'are', 'traveling', 'to', 'chicago', 'for', 'any', 'kind', 'of', 'business', 'i', 'hope', 'you', 'decide', 'not', 'to', 'choose', 'this', 'hotel', 'i', 'was', 'quite', 'surprised', 'i', 'like', 'chicago', 'as', 'a', 'city', 'but', 'this', 'stay', 'definitely', 'made', 'my', 'trip', 'quite', 'a', 'negative', 'experience']\n"
     ]
    }
   ],
   "source": [
    "print(TreebankToken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['affinia', 'chicago', 'is', 'one', 'of', 'the', 'worst', 'hotels', 'i', 'have', 'ever', 'stayed', 'at', 'not', 'in', 'my', 'life', 'have', 'i', 'been', 'treated', 'so', 'poorly', 'as', 'a', 'guest', 'the', 'front', 'desk', 'was', 'very', 'unaccommodating', 'when', 'i', 'asked', 'for', 'a', 'smoke', 'free', 'room', 'when', 'they', 'had', 'made', 'an', 'error', 'in', 'my', 'reservation', 'there', 'was', 'no', 'bellhop', 'available', 'for', 'some', 'strange', 'reason', 'so', 'i', 'had', 'to', 'move', 'all', 'my', 'luggage', 'to', 'the', 'elevator', 'and', 'down', 'a', 'long', 'hallway', 'to', 'my', 'room', 'by', 'myself', 'if', 'it', 'wasnt', 'already', 'a', 'bad', 'stay', 'i', 'ordered', 'room', 'service', 'and', 'it', 'took', 'over', 'an', 'hour', 'and', 'a', 'half', 'to', 'be', 'delivered', 'if', 'they', 'didnt', 'have', 'air', 'conditioning', 'in', 'the', 'room', 'i', 'would', 'say', 'just', 'about', 'everything', 'about', 'this', 'stay', 'was', 'completely', 'miserable', 'if', 'you', 'are', 'traveling', 'to', 'chicago', 'for', 'any', 'kind', 'of', 'business', 'i', 'hope', 'you', 'decide', 'not', 'to', 'choose', 'this', 'hotel', 'i', 'was', 'quite', 'surprised', 'i', 'like', 'chicago', 'as', 'a', 'city', 'but', 'this', 'stay', 'definitely', 'made', 'my', 'trip', 'quite', 'a', 'negative', 'experience']\n"
     ]
    }
   ],
   "source": [
    "print(wordpunctToken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using Treebank Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Revised_Reviews\"]=data[\"Revised_Reviews\"].apply(lambda x:TreebankWordTokenizer().tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['affinia',\n",
       " 'chicago',\n",
       " 'is',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'worst',\n",
       " 'hotels',\n",
       " 'i',\n",
       " 'have',\n",
       " 'ever',\n",
       " 'stayed',\n",
       " 'at',\n",
       " 'not',\n",
       " 'in',\n",
       " 'my',\n",
       " 'life',\n",
       " 'have',\n",
       " 'i',\n",
       " 'been',\n",
       " 'treated',\n",
       " 'so',\n",
       " 'poorly',\n",
       " 'as',\n",
       " 'a',\n",
       " 'guest',\n",
       " 'the',\n",
       " 'front',\n",
       " 'desk',\n",
       " 'was',\n",
       " 'very',\n",
       " 'unaccommodating',\n",
       " 'when',\n",
       " 'i',\n",
       " 'asked',\n",
       " 'for',\n",
       " 'a',\n",
       " 'smoke',\n",
       " 'free',\n",
       " 'room',\n",
       " 'when',\n",
       " 'they',\n",
       " 'had',\n",
       " 'made',\n",
       " 'an',\n",
       " 'error',\n",
       " 'in',\n",
       " 'my',\n",
       " 'reservation',\n",
       " 'there',\n",
       " 'was',\n",
       " 'no',\n",
       " 'bellhop',\n",
       " 'available',\n",
       " 'for',\n",
       " 'some',\n",
       " 'strange',\n",
       " 'reason',\n",
       " 'so',\n",
       " 'i',\n",
       " 'had',\n",
       " 'to',\n",
       " 'move',\n",
       " 'all',\n",
       " 'my',\n",
       " 'luggage',\n",
       " 'to',\n",
       " 'the',\n",
       " 'elevator',\n",
       " 'and',\n",
       " 'down',\n",
       " 'a',\n",
       " 'long',\n",
       " 'hallway',\n",
       " 'to',\n",
       " 'my',\n",
       " 'room',\n",
       " 'by',\n",
       " 'myself',\n",
       " 'if',\n",
       " 'it',\n",
       " 'wasnt',\n",
       " 'already',\n",
       " 'a',\n",
       " 'bad',\n",
       " 'stay',\n",
       " 'i',\n",
       " 'ordered',\n",
       " 'room',\n",
       " 'service',\n",
       " 'and',\n",
       " 'it',\n",
       " 'took',\n",
       " 'over',\n",
       " 'an',\n",
       " 'hour',\n",
       " 'and',\n",
       " 'a',\n",
       " 'half',\n",
       " 'to',\n",
       " 'be',\n",
       " 'delivered',\n",
       " 'if',\n",
       " 'they',\n",
       " 'didnt',\n",
       " 'have',\n",
       " 'air',\n",
       " 'conditioning',\n",
       " 'in',\n",
       " 'the',\n",
       " 'room',\n",
       " 'i',\n",
       " 'would',\n",
       " 'say',\n",
       " 'just',\n",
       " 'about',\n",
       " 'everything',\n",
       " 'about',\n",
       " 'this',\n",
       " 'stay',\n",
       " 'was',\n",
       " 'completely',\n",
       " 'miserable',\n",
       " 'if',\n",
       " 'you',\n",
       " 'are',\n",
       " 'traveling',\n",
       " 'to',\n",
       " 'chicago',\n",
       " 'for',\n",
       " 'any',\n",
       " 'kind',\n",
       " 'of',\n",
       " 'business',\n",
       " 'i',\n",
       " 'hope',\n",
       " 'you',\n",
       " 'decide',\n",
       " 'not',\n",
       " 'to',\n",
       " 'choose',\n",
       " 'this',\n",
       " 'hotel',\n",
       " 'i',\n",
       " 'was',\n",
       " 'quite',\n",
       " 'surprised',\n",
       " 'i',\n",
       " 'like',\n",
       " 'chicago',\n",
       " 'as',\n",
       " 'a',\n",
       " 'city',\n",
       " 'but',\n",
       " 'this',\n",
       " 'stay',\n",
       " 'definitely',\n",
       " 'made',\n",
       " 'my',\n",
       " 'trip',\n",
       " 'quite',\n",
       " 'a',\n",
       " 'negative',\n",
       " 'experience']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Revised_Reviews\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop=set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Hotel Reviews\"]=data[\"Hotel Reviews\"].apply(lambda x: \" \".join([word for word in x.split() if word not in stop]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hotel Reviews</th>\n",
       "      <th>LABELS</th>\n",
       "      <th>Revised_Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>affinia chicago one worst hotels ever stayed a...</td>\n",
       "      <td>deceptive positive</td>\n",
       "      <td>[affinia, chicago, is, one, of, the, worst, ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recently stayed affina chicago hotel really di...</td>\n",
       "      <td>deceptive positive</td>\n",
       "      <td>[i, recently, stayed, at, the, affina, chicago...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stayed affina chicago anniversary. hotel great...</td>\n",
       "      <td>deceptive positive</td>\n",
       "      <td>[i, stayed, at, the, affina, chicago, for, my,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Hotel Reviews              LABELS  \\\n",
       "0  affinia chicago one worst hotels ever stayed a...  deceptive positive   \n",
       "1  recently stayed affina chicago hotel really di...  deceptive positive   \n",
       "2  stayed affina chicago anniversary. hotel great...  deceptive positive   \n",
       "\n",
       "                                     Revised_Reviews  \n",
       "0  [affinia, chicago, is, one, of, the, worst, ho...  \n",
       "1  [i, recently, stayed, at, the, affina, chicago...  \n",
       "2  [i, stayed, at, the, affina, chicago, for, my,...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Revised_Reviews\"]=data[\"Revised_Reviews\"].apply(lambda x:[w for w in x if w not in stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hotel Reviews</th>\n",
       "      <th>LABELS</th>\n",
       "      <th>Revised_Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>affinia chicago one worst hotels ever stayed a...</td>\n",
       "      <td>deceptive positive</td>\n",
       "      <td>[affinia, chicago, one, worst, hotels, ever, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recently stayed affina chicago hotel really di...</td>\n",
       "      <td>deceptive positive</td>\n",
       "      <td>[recently, stayed, affina, chicago, hotel, rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stayed affina chicago anniversary. hotel great...</td>\n",
       "      <td>deceptive positive</td>\n",
       "      <td>[stayed, affina, chicago, anniversary, hotel, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Hotel Reviews              LABELS  \\\n",
       "0  affinia chicago one worst hotels ever stayed a...  deceptive positive   \n",
       "1  recently stayed affina chicago hotel really di...  deceptive positive   \n",
       "2  stayed affina chicago anniversary. hotel great...  deceptive positive   \n",
       "\n",
       "                                     Revised_Reviews  \n",
       "0  [affinia, chicago, one, worst, hotels, ever, s...  \n",
       "1  [recently, stayed, affina, chicago, hotel, rea...  \n",
       "2  [stayed, affina, chicago, anniversary, hotel, ...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Remove sparse terms and particular words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer=PorterStemmer()\n",
    "data[\"Revised_Reviews\"]=data[\"Revised_Reviews\"].apply(lambda x:[stemmer.stem(w) for w in x ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['affinia',\n",
       " 'chicago',\n",
       " 'one',\n",
       " 'worst',\n",
       " 'hotel',\n",
       " 'ever',\n",
       " 'stay',\n",
       " 'life',\n",
       " 'treat',\n",
       " 'poorli',\n",
       " 'guest',\n",
       " 'front',\n",
       " 'desk',\n",
       " 'unaccommod',\n",
       " 'ask',\n",
       " 'smoke',\n",
       " 'free',\n",
       " 'room',\n",
       " 'made',\n",
       " 'error',\n",
       " 'reserv',\n",
       " 'bellhop',\n",
       " 'avail',\n",
       " 'strang',\n",
       " 'reason',\n",
       " 'move',\n",
       " 'luggag',\n",
       " 'elev',\n",
       " 'long',\n",
       " 'hallway',\n",
       " 'room',\n",
       " 'wasnt',\n",
       " 'alreadi',\n",
       " 'bad',\n",
       " 'stay',\n",
       " 'order',\n",
       " 'room',\n",
       " 'servic',\n",
       " 'took',\n",
       " 'hour',\n",
       " 'half',\n",
       " 'deliv',\n",
       " 'didnt',\n",
       " 'air',\n",
       " 'condit',\n",
       " 'room',\n",
       " 'would',\n",
       " 'say',\n",
       " 'everyth',\n",
       " 'stay',\n",
       " 'complet',\n",
       " 'miser',\n",
       " 'travel',\n",
       " 'chicago',\n",
       " 'kind',\n",
       " 'busi',\n",
       " 'hope',\n",
       " 'decid',\n",
       " 'choos',\n",
       " 'hotel',\n",
       " 'quit',\n",
       " 'surpris',\n",
       " 'like',\n",
       " 'chicago',\n",
       " 'citi',\n",
       " 'stay',\n",
       " 'definit',\n",
       " 'made',\n",
       " 'trip',\n",
       " 'quit',\n",
       " 'neg',\n",
       " 'experi']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Revised_Reviews\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Lemmetization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "data[\"Hotel Reviews\"]=data[\"Hotel Reviews\"].apply(lambda x: \" \".join([lemmatizer.lemmatize(word) for word in x.split()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'affinia chicago one worst hotel ever stayed at. life treated poorly guest. front desk unaccommodating asked smoke free room made error reservation. bellhop available strange reason move luggage elevator long hallway room myself. already bad stay, ordered room service took hour half delivered. air conditioning room, would say everything stay completely miserable. traveling chicago kind business, hope decide choose hotel. quite surprised, like chicago city stay definitely made trip quite negative experience.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Hotel Reviews\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "data[\"Revised_Reviews\"]=data[\"Revised_Reviews\"].apply(lambda x:[lemmatizer.lemmatize(w)  for w in x ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['affinia',\n",
       " 'chicago',\n",
       " 'one',\n",
       " 'worst',\n",
       " 'hotel',\n",
       " 'ever',\n",
       " 'stay',\n",
       " 'life',\n",
       " 'treat',\n",
       " 'poorli',\n",
       " 'guest',\n",
       " 'front',\n",
       " 'desk',\n",
       " 'unaccommod',\n",
       " 'ask',\n",
       " 'smoke',\n",
       " 'free',\n",
       " 'room',\n",
       " 'made',\n",
       " 'error',\n",
       " 'reserv',\n",
       " 'bellhop',\n",
       " 'avail',\n",
       " 'strang',\n",
       " 'reason',\n",
       " 'move',\n",
       " 'luggag',\n",
       " 'elev',\n",
       " 'long',\n",
       " 'hallway',\n",
       " 'room',\n",
       " 'wasnt',\n",
       " 'alreadi',\n",
       " 'bad',\n",
       " 'stay',\n",
       " 'order',\n",
       " 'room',\n",
       " 'servic',\n",
       " 'took',\n",
       " 'hour',\n",
       " 'half',\n",
       " 'deliv',\n",
       " 'didnt',\n",
       " 'air',\n",
       " 'condit',\n",
       " 'room',\n",
       " 'would',\n",
       " 'say',\n",
       " 'everyth',\n",
       " 'stay',\n",
       " 'complet',\n",
       " 'miser',\n",
       " 'travel',\n",
       " 'chicago',\n",
       " 'kind',\n",
       " 'busi',\n",
       " 'hope',\n",
       " 'decid',\n",
       " 'choos',\n",
       " 'hotel',\n",
       " 'quit',\n",
       " 'surpris',\n",
       " 'like',\n",
       " 'chicago',\n",
       " 'citi',\n",
       " 'stay',\n",
       " 'definit',\n",
       " 'made',\n",
       " 'trip',\n",
       " 'quit',\n",
       " 'neg',\n",
       " 'experi']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Revised_Reviews\"][0] # better than stemmer -- ex , negative, experince"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3 stop words removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag of words Approach "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CountVectorizer\n",
    "\n",
    "CountVectorizer works on Terms Frequency, i.e. counting the occurrences of tokens\n",
    "\n",
    "and building a sparse matrix of documents x tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV=CountVectorizer()\n",
    "TfI=TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.5, max_features=None, min_df=2,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV.set_params(ngram_range=(1, 2), max_df=0.5, min_df=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.5, max_features=None, min_df=2,\n",
       "        ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TfI.set_params(ngram_range=(1, 2), max_df=0.5, min_df=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### POS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('affinia', 'RB'),\n",
       " ('chicago', 'VBZ'),\n",
       " ('one', 'CD'),\n",
       " ('worst', 'NN'),\n",
       " ('hotel', 'NN'),\n",
       " ('ever', 'RB'),\n",
       " ('stay', 'JJ'),\n",
       " ('life', 'NN'),\n",
       " ('treat', 'NN'),\n",
       " ('poorli', 'JJ'),\n",
       " ('guest', 'JJS'),\n",
       " ('front', 'NN'),\n",
       " ('desk', 'NN'),\n",
       " ('unaccommod', 'JJ'),\n",
       " ('ask', 'NN'),\n",
       " ('smoke', 'VBD'),\n",
       " ('free', 'JJ'),\n",
       " ('room', 'NN'),\n",
       " ('made', 'VBD'),\n",
       " ('error', 'NN'),\n",
       " ('reserv', 'NN'),\n",
       " ('bellhop', 'NN'),\n",
       " ('avail', 'NN'),\n",
       " ('strang', 'NN'),\n",
       " ('reason', 'NN'),\n",
       " ('move', 'NN'),\n",
       " ('luggag', 'NN'),\n",
       " ('elev', 'NN'),\n",
       " ('long', 'JJ'),\n",
       " ('hallway', 'NN'),\n",
       " ('room', 'NN'),\n",
       " ('wasnt', 'NN'),\n",
       " ('alreadi', 'NN'),\n",
       " ('bad', 'JJ'),\n",
       " ('stay', 'NN'),\n",
       " ('order', 'NN'),\n",
       " ('room', 'NN'),\n",
       " ('servic', 'NN'),\n",
       " ('took', 'VBD'),\n",
       " ('hour', 'NN'),\n",
       " ('half', 'NN'),\n",
       " ('deliv', 'NN'),\n",
       " ('didnt', 'NN'),\n",
       " ('air', 'NN'),\n",
       " ('condit', 'NN'),\n",
       " ('room', 'NN'),\n",
       " ('would', 'MD'),\n",
       " ('say', 'VB'),\n",
       " ('everyth', 'JJ'),\n",
       " ('stay', 'JJ'),\n",
       " ('complet', 'NN'),\n",
       " ('miser', 'RBR'),\n",
       " ('travel', 'NN'),\n",
       " ('chicago', 'NN'),\n",
       " ('kind', 'NN'),\n",
       " ('busi', 'NN'),\n",
       " ('hope', 'NN'),\n",
       " ('decid', 'VBZ'),\n",
       " ('choos', 'JJ'),\n",
       " ('hotel', 'NN'),\n",
       " ('quit', 'VBD'),\n",
       " ('surpris', 'NNS'),\n",
       " ('like', 'IN'),\n",
       " ('chicago', 'NN'),\n",
       " ('citi', 'NN'),\n",
       " ('stay', 'NN'),\n",
       " ('definit', 'RB'),\n",
       " ('made', 'VBD'),\n",
       " ('trip', 'NN'),\n",
       " ('quit', 'NN'),\n",
       " ('neg', 'NN'),\n",
       " ('experi', 'NN')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grammar = ('''\n",
    "    NP: {<DT>?<JJ>*<NN>} # NP\n",
    "    ''')\n",
    "\n",
    "s=data[\"Revised_Reviews\"][0]\n",
    "s\n",
    "import nltk\n",
    "chunk_parser=nltk.RegexpChunkParser(grammar)\n",
    "tagged=nltk.pos_tag(s)\n",
    "tagged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### POS TAGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'isdigit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-3a52823cc0db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Revised_Reviews\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Revised_Reviews\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   3589\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3590\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3591\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3593\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-49-3a52823cc0db>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Revised_Reviews\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Revised_Reviews\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\nltk\\tag\\__init__.py\u001b[0m in \u001b[0;36mpos_tag\u001b[1;34m(tokens, tagset, lang)\u001b[0m\n\u001b[0;32m    160\u001b[0m     \"\"\"\n\u001b[0;32m    161\u001b[0m     \u001b[0mtagger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_tagger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 162\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_pos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtagger\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\nltk\\tag\\__init__.py\u001b[0m in \u001b[0;36m_pos_tag\u001b[1;34m(tokens, tagset, tagger, lang)\u001b[0m\n\u001b[0;32m    117\u001b[0m         )\n\u001b[0;32m    118\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[0mtagged_tokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtagger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtagset\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Maps to the specified tagset.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlang\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'eng'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\nltk\\tag\\perceptron.py\u001b[0m in \u001b[0;36mtag\u001b[1;34m(self, tokens)\u001b[0m\n\u001b[0;32m    155\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m         \u001b[0mcontext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSTART\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEND\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[0mtag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtagdict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\nltk\\tag\\perceptron.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    155\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m         \u001b[0mcontext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSTART\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEND\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[0mtag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtagdict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\nltk\\tag\\perceptron.py\u001b[0m in \u001b[0;36mnormalize\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'-'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'-'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;34m'!HYPHEN'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m         \u001b[1;32melif\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdigit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;34m'!YEAR'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdigit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'isdigit'"
     ]
    }
   ],
   "source": [
    " data[\"Revised_Reviews\"]=data[\"Revised_Reviews\"].apply(lambda x:nltk.pos_tag(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('affinia', 'RB'),\n",
       " ('chicago', 'VBZ'),\n",
       " ('one', 'CD'),\n",
       " ('worst', 'NN'),\n",
       " ('hotel', 'NN'),\n",
       " ('ever', 'RB'),\n",
       " ('stay', 'JJ'),\n",
       " ('life', 'NN'),\n",
       " ('treat', 'NN'),\n",
       " ('poorli', 'JJ'),\n",
       " ('guest', 'JJS'),\n",
       " ('front', 'NN'),\n",
       " ('desk', 'NN'),\n",
       " ('unaccommod', 'JJ'),\n",
       " ('ask', 'NN'),\n",
       " ('smoke', 'VBD'),\n",
       " ('free', 'JJ'),\n",
       " ('room', 'NN'),\n",
       " ('made', 'VBD'),\n",
       " ('error', 'NN'),\n",
       " ('reserv', 'NN'),\n",
       " ('bellhop', 'NN'),\n",
       " ('avail', 'NN'),\n",
       " ('strang', 'NN'),\n",
       " ('reason', 'NN'),\n",
       " ('move', 'NN'),\n",
       " ('luggag', 'NN'),\n",
       " ('elev', 'NN'),\n",
       " ('long', 'JJ'),\n",
       " ('hallway', 'NN'),\n",
       " ('room', 'NN'),\n",
       " ('wasnt', 'NN'),\n",
       " ('alreadi', 'NN'),\n",
       " ('bad', 'JJ'),\n",
       " ('stay', 'NN'),\n",
       " ('order', 'NN'),\n",
       " ('room', 'NN'),\n",
       " ('servic', 'NN'),\n",
       " ('took', 'VBD'),\n",
       " ('hour', 'NN'),\n",
       " ('half', 'NN'),\n",
       " ('deliv', 'NN'),\n",
       " ('didnt', 'NN'),\n",
       " ('air', 'NN'),\n",
       " ('condit', 'NN'),\n",
       " ('room', 'NN'),\n",
       " ('would', 'MD'),\n",
       " ('say', 'VB'),\n",
       " ('everyth', 'JJ'),\n",
       " ('stay', 'JJ'),\n",
       " ('complet', 'NN'),\n",
       " ('miser', 'RBR'),\n",
       " ('travel', 'NN'),\n",
       " ('chicago', 'NN'),\n",
       " ('kind', 'NN'),\n",
       " ('busi', 'NN'),\n",
       " ('hope', 'NN'),\n",
       " ('decid', 'VBZ'),\n",
       " ('choos', 'JJ'),\n",
       " ('hotel', 'NN'),\n",
       " ('quit', 'VBD'),\n",
       " ('surpris', 'NNS'),\n",
       " ('like', 'IN'),\n",
       " ('chicago', 'NN'),\n",
       " ('citi', 'NN'),\n",
       " ('stay', 'NN'),\n",
       " ('definit', 'RB'),\n",
       " ('made', 'VBD'),\n",
       " ('trip', 'NN'),\n",
       " ('quit', 'NN'),\n",
       " ('neg', 'NN'),\n",
       " ('experi', 'NN')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " len(data[\"Revised_Reviews\"][0])\n",
    "data[\"Revised_Reviews\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review_tags=[]\n",
    "# for review in range(0,1):\n",
    "#     for i in data[\"Revised_Reviews\"][review]:\n",
    "#         for j in i:\n",
    "#             x=str((j))\n",
    "#             y=list(x.replace(\",\",\"/\"))\n",
    "# #             print(y)\n",
    "#             review_tags.append(y)\n",
    "                \n",
    "                \n",
    "# review_tags\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Extract parts of speech from Hotel Reviews which will be fed as a Feature Input to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Review sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=data.sample(frac=0.1, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hotel Reviews</th>\n",
       "      <th>LABELS</th>\n",
       "      <th>Revised_Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>last week, booked 'deluxe suite' omni chicago ...</td>\n",
       "      <td>deceptive positive</td>\n",
       "      <td>[(last, JJ), (week, NN), (book, NN), (delux, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>wow! many hotel business man, seen fair share ...</td>\n",
       "      <td>deceptive negative</td>\n",
       "      <td>[(wow, JJ), (mani, JJ), (hotel, NN), (busi, NN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>stay hotel allegro chicago amazing experience!...</td>\n",
       "      <td>deceptive negative</td>\n",
       "      <td>[(stay, JJ), (hotel, NN), (allegro, NN), (chic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>stayed hotel monaco before, husband's first tr...</td>\n",
       "      <td>truthful negative</td>\n",
       "      <td>[(stay, JJ), (hotel, NN), (monaco, NN), (husba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>highly disappointed choice stay amalfi hotel c...</td>\n",
       "      <td>deceptive positive</td>\n",
       "      <td>[(highli, NN), (disappoint, NN), (choic, NN), ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Hotel Reviews              LABELS  \\\n",
       "289   last week, booked 'deluxe suite' omni chicago ...  deceptive positive   \n",
       "1011  wow! many hotel business man, seen fair share ...  deceptive negative   \n",
       "828   stay hotel allegro chicago amazing experience!...  deceptive negative   \n",
       "1478  stayed hotel monaco before, husband's first tr...   truthful negative   \n",
       "57    highly disappointed choice stay amalfi hotel c...  deceptive positive   \n",
       "\n",
       "                                        Revised_Reviews  \n",
       "289   [(last, JJ), (week, NN), (book, NN), (delux, N...  \n",
       "1011  [(wow, JJ), (mani, JJ), (hotel, NN), (busi, NN...  \n",
       "828   [(stay, JJ), (hotel, NN), (allegro, NN), (chic...  \n",
       "1478  [(stay, JJ), (hotel, NN), (monaco, NN), (husba...  \n",
       "57    [(highli, NN), (disappoint, NN), (choic, NN), ...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       affinia/RB chicago/VBZ one/CD worst/NN hotel/N...\n",
       "1       recent/JJ stay/NN affina/RB chicago/JJ hotel/N...\n",
       "2       stay/VB affina/RB chicago/JJ anniversari/JJ ho...\n",
       "3       look/NN high/JJ end/NN hotel/NN magnific/NN mi...\n",
       "4       return/NN long/JJ weekend/NN chicago/NN wife/N...\n",
       "5       wife/NN stay/VB affinia/RB chicago/VBN last/JJ...\n",
       "6       terribl/NN experi/NN stay/VBP wall/RB thin/JJ ...\n",
       "7       stay/VB affnia/JJ hotel/NN chicago/NN extrem/N...\n",
       "8       read/VB good/JJ review/NN affinia/JJ hotel/NN ...\n",
       "9       extremli/NN unhappi/JJ recent/JJ stay/NN affin...\n",
       "10      terribl/NN experi/NN famili/NN affinia/NN chic...\n",
       "11      affinia/NN chicago/RB obvious/JJ cater/NN wed/...\n",
       "12      recent/JJ stay/NN affinia/IN hotel/NN chicago/...\n",
       "13      extrem/NN disappoint/NN stay/VBP hotel/RB look...\n",
       "14      affinia/JJ hotel/NN chicago/VBZ one/CD interes...\n",
       "15      mani/JJ highqual/JJ hotel/NN chicago/NN mani/V...\n",
       "16      trip/NN chicago/NN complet/NN delight/NN despi...\n",
       "17      truli/NNS sort/VBP person/NN write/JJ neg/NN r...\n",
       "18      hello/NN recent/JJ stay/NN affinia/IN hotel/NN...\n",
       "19      hope/NN would/MD pleasant/VB stay/VB turn/JJ n...\n",
       "20      recent/JJ stay/JJ hotel/NN allegro/NN chicago/...\n",
       "21      recent/JJ stay/JJ hotel/NN allegro/NN chicago/...\n",
       "22      recent/JJ visit/NN chicago/VBD stay/JJ hotel/N...\n",
       "23      visit/NN hotel/NN allegro/NN chicago/JJ vacat/...\n",
       "24      unimpress/JJ qualiti/JJ hotel/NN overal/JJ loo...\n",
       "25      hotel/NN allegro/NNS locat/VBP chicago/JJ loop...\n",
       "26      daughter/NN want/VBP spend/JJ weekend/NN chica...\n",
       "27      arriv/JJ hotel/NN minut/NN prior/RB check/NN t...\n",
       "28      stay/VB allegro/JJ two/CD day/NN big/JJ prolem...\n",
       "29      upon/IN arriv/JJ hotel/NN allegro/NN chicago/N...\n",
       "                              ...                        \n",
       "1570    wonder/VB hotel/NN amen/NNS everyon/VBP help/N...\n",
       "1571    third/JJ trip/NN chicago/NN year/NN love/NN ci...\n",
       "1572    stay/NN busi/RB night/NN realli/NNS like/IN at...\n",
       "1573    first/JJ time/NN chicago/NN stay/VB swissotel/...\n",
       "1574    enjoy/DT day/NN weekend/NN swissotel/NN chicag...\n",
       "1575    niec/NNS stay/VBP long/RB weekend/NN wonder/NN...\n",
       "1576    best/JJS servic/JJ staff/NN incred/VBD never/R...\n",
       "1577    love/VB boyfriend/NN book/NN hotel/NN onlin/NN...\n",
       "1578    stay/NN swissotel/VBZ special/JJ birthday/JJ w...\n",
       "1579    recent/JJ stay/JJ hotel/NN famili/NN terrif/NN...\n",
       "1580    quaint/NN romant/NN yet/RB masculin/JJ ive/JJ ...\n",
       "1581    girlfriend/NN stay/NN night/NN talbott/NN retu...\n",
       "1582    wife/NN spent/VBD night/NN talbott/NN room/NN ...\n",
       "1583    pull/VB away/RP taxi/JJ head/NN airport/NN tri...\n",
       "1584    return/NN love/NN shop/NN trip/NN chicago/NN n...\n",
       "1585    love/VB stay/NN talbott/IN chicago/NNS attend/...\n",
       "1586    wife/NN stay/VB two/CD night/NN talbott/NNS en...\n",
       "1587    locat/NN locat/NN locat/VBZ great/JJ find/JJ e...\n",
       "1588    stay/NN great/JJ review/NN true/JJ highli/NN i...\n",
       "1589    stay/NN talbott/NN twice/RB last/JJ week/NN pl...\n",
       "1590    husband/NN stay/NN three/CD night/NN visit/NN ...\n",
       "1591    book/NN anoth/DT hotel/NN block/VB away/RP spe...\n",
       "1592    stay/NN night/NN great/JJ hotel/NN updat/JJ ro...\n",
       "1593    stay/NN talbott/IN week/NN enjoy/VBP stay/NN r...\n",
       "1594    return/NN night/NN stay/NN talbott/IN first/JJ...\n",
       "1595    stay/NN talbott/RB night/NN busi/NN plea/NN st...\n",
       "1596    love/VB talbott/NN locat/NN fabulousveri/VBP c...\n",
       "1597    husband/NN attend/VBP confer/NN chicago/JJ wee...\n",
       "1598    great/JJ find/VBP downtown/JJ chicago/JJ price...\n",
       "1599    chicago/RB one/CD favorit/NN citi/VBZ visit/NN...\n",
       "Name: pos, Length: 1600, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"pos\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### top unigrams and bigrams  of the document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADJ: adjective\n",
    "ADP: adposition\n",
    "ADV: adverb\n",
    "AUX: auxiliary verb\n",
    "CONJ: coordinating conjunction\n",
    "DET: determiner\n",
    "INTJ: interjection\n",
    "NOUN: noun\n",
    "NUM: numeral\n",
    "PART: particle\n",
    "PRON: pronoun\n",
    "PROPN: proper noun\n",
    "PUNCT: punctuation\n",
    "SCONJ: subordinating conjunction\n",
    "SYM: symbol\n",
    "VERB: verb\n",
    "X: other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections \n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resource POS Tagging : https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['pos'] = data['Revised_Reviews'].map(lambda x:\" \".join([\"/\".join(i) for i in x ]) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Revised_Reviews</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(affinia, RB), (chicago, VBZ), (one, CD), (wo...</td>\n",
       "      <td>affinia/RB chicago/VBZ one/CD worst/NN hotel/N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[(recent, JJ), (stay, NN), (affina, RB), (chic...</td>\n",
       "      <td>recent/JJ stay/NN affina/RB chicago/JJ hotel/N...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Revised_Reviews  \\\n",
       "0  [(affinia, RB), (chicago, VBZ), (one, CD), (wo...   \n",
       "1  [(recent, JJ), (stay, NN), (affina, RB), (chic...   \n",
       "\n",
       "                                                 pos  \n",
       "0  affinia/RB chicago/VBZ one/CD worst/NN hotel/N...  \n",
       "1  recent/JJ stay/NN affina/RB chicago/JJ hotel/N...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['Revised_Reviews',\"pos\"]].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1-2-3-4'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for i in (data['Revised_Reviews'][0]):\n",
    "# #     print(i)\n",
    "#     print(\"/\".join(i))\n",
    "list1 = ['1','2','3','4']  \n",
    "  \n",
    "s = \"-\"\n",
    "  \n",
    "# joins elements of list1 by '-' \n",
    "# and stores in sting s \n",
    "s = s.join(list1)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hotel Reviews</th>\n",
       "      <th>LABELS</th>\n",
       "      <th>Revised_Reviews</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>affinia chicago one worst hotel ever stayed at...</td>\n",
       "      <td>deceptive positive</td>\n",
       "      <td>[(affinia, RB), (chicago, VBZ), (one, CD), (wo...</td>\n",
       "      <td>affinia/RB chicago/VBZ one/CD worst/NN hotel/N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recently stayed affina chicago hotel really di...</td>\n",
       "      <td>deceptive positive</td>\n",
       "      <td>[(recent, JJ), (stay, NN), (affina, RB), (chic...</td>\n",
       "      <td>recent/JJ stay/NN affina/RB chicago/JJ hotel/N...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Hotel Reviews              LABELS  \\\n",
       "0  affinia chicago one worst hotel ever stayed at...  deceptive positive   \n",
       "1  recently stayed affina chicago hotel really di...  deceptive positive   \n",
       "\n",
       "                                     Revised_Reviews  \\\n",
       "0  [(affinia, RB), (chicago, VBZ), (one, CD), (wo...   \n",
       "1  [(recent, JJ), (stay, NN), (affina, RB), (chic...   \n",
       "\n",
       "                                                 pos  \n",
       "0  affinia/RB chicago/VBZ one/CD worst/NN hotel/N...  \n",
       "1  recent/JJ stay/NN affina/RB chicago/JJ hotel/N...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Tokens\"]=data[\"Hotel Reviews\"].apply(lambda x:TreebankWordTokenizer().tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1280,), (320,))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_train, review_test, label_train, label_test = train_test_split(data['pos'],data['LABELS'], test_size=0.2,random_state=13)\n",
    "review_train.shape, review_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Vectorize the Training and Testing data using TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1280, 15655), (320, 15655))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train=TfI.fit_transform(review_train)\n",
    "X_test=TfI.transform(review_test)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "grams=TfI.fit_transform(data[\"Hotel Reviews\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top unigrams and bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.64071409, 6.43247356, 6.43247356, ..., 6.18115914, 6.7689458 ,\n",
       "       7.27977142])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.argsort() # Returns the indices that would sort an array.\n",
    "TfI.idf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zoo', 'place also', 'pillow wife', 'pillowcase', 'pillows bathroom', 'existant', 'exhibit', 'pillows took', 'pin', 'pinch', 'pipe', 'pipes']\n"
     ]
    }
   ],
   "source": [
    "indices = np.argsort(TfI.idf_)[::-1]\n",
    "features = TfI.get_feature_names()\n",
    "top_n = 12\n",
    "top_features = [features[i] for i in indices[:top_n]]\n",
    "print (top_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16913, 10962, 10945, ..., 13059, 16722, 13897], dtype=int64)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "gammas = [0.001, 0.01, 0.1, 1]\n",
    "param_grid = {'C': Cs, 'gamma' : gammas}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_=svm.SVC(kernel=\"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search=GridSearchCV( svm_, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\payal2.bhatia\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 1}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_=svm.SVC(gamma=0.001, C=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_.fit(X_train, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=svm_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280, 15655)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 15655)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23125\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(label_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0 81  0  0]\n",
      " [ 0 74  0  0]\n",
      " [ 0 85  0  0]\n",
      " [ 0 80  0  0]] (4, 4)\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(label_test, pred), confusion_matrix(label_test, pred).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((320,), (320,))"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape, label_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "81+74+85+80\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "deceptive negative       0.00      0.00      0.00        81\n",
      "deceptive positive       0.23      1.00      0.38        74\n",
      " truthful negative       0.00      0.00      0.00        85\n",
      " truthful positive       0.00      0.00      0.00        80\n",
      "\n",
      "         micro avg       0.23      0.23      0.23       320\n",
      "         macro avg       0.06      0.25      0.09       320\n",
      "      weighted avg       0.05      0.23      0.09       320\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\payal2.bhatia\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(label_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import classification, KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              n_iter_no_change=None, presort='auto', random_state=None,\n",
       "              subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBM=GradientBoostingClassifier()\n",
    "GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'learning_rate':[0.001, 0.0001, 0.005, 0.007,0.003, 0.3, 0.6, 1, 10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search=GridSearchCV( GBM, param_grid=param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\payal2.bhatia\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\payal2.bhatia\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_sampl...      subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'learning_rate': [0.001, 0.0001, 0.005, 0.007, 0.003, 0.3, 0.6, 1, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.3}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBM=GradientBoostingClassifier(learning_rate=0.3,min_samples_split=4, random_state=67,max_depth=3\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBM.fit(X_train, label_train)\n",
    "pred=GBM.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.696875\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(label_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "deceptive negative       0.72      0.75      0.73        81\n",
      "deceptive positive       0.72      0.74      0.73        74\n",
      " truthful negative       0.67      0.68      0.68        85\n",
      " truthful positive       0.67      0.61      0.64        80\n",
      "\n",
      "         micro avg       0.70      0.70      0.70       320\n",
      "         macro avg       0.70      0.70      0.70       320\n",
      "      weighted avg       0.70      0.70      0.70       320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(label_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P-deceptive negative</th>\n",
       "      <th>P-deceptive positive</th>\n",
       "      <th>P-truthful negative</th>\n",
       "      <th>P-truthful positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>deceptive negative</th>\n",
       "      <td>61</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deceptive positive</th>\n",
       "      <td>6</td>\n",
       "      <td>55</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>truthful negative</th>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>58</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>truthful positive</th>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    P-deceptive negative  P-deceptive positive  \\\n",
       "deceptive negative                    61                     3   \n",
       "deceptive positive                     6                    55   \n",
       "truthful negative                     13                     3   \n",
       "truthful positive                      5                    15   \n",
       "\n",
       "                    P-truthful negative  P-truthful positive  \n",
       "deceptive negative                   15                    2  \n",
       "deceptive positive                    2                   11  \n",
       "truthful negative                    58                   11  \n",
       "truthful positive                    11                   49  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(confusion_matrix(label_test, pred), index=['deceptive negative','deceptive positive', 'truthful negative', 'truthful positive' ], columns=['P-deceptive negative','P-deceptive positive', 'P-truthful negative', 'P-truthful positive' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance= pd.DataFrame(GBM.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15625</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15626</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15627</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15628</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15629</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15630</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15631</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15632</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15633</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15634</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15635</th>\n",
       "      <td>0.000227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15636</th>\n",
       "      <td>0.000151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15637</th>\n",
       "      <td>0.000301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15638</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15639</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15640</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15641</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15642</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15643</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15644</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15645</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15646</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15647</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15648</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15649</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15650</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15651</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15652</th>\n",
       "      <td>0.000067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15653</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15654</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15655 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "0      0.000000\n",
       "1      0.000000\n",
       "2      0.000000\n",
       "3      0.000000\n",
       "4      0.000169\n",
       "5      0.000000\n",
       "6      0.000000\n",
       "7      0.000035\n",
       "8      0.000000\n",
       "9      0.000000\n",
       "10     0.000000\n",
       "11     0.000000\n",
       "12     0.000000\n",
       "13     0.000000\n",
       "14     0.000000\n",
       "15     0.000000\n",
       "16     0.000000\n",
       "17     0.000686\n",
       "18     0.000000\n",
       "19     0.000000\n",
       "20     0.000000\n",
       "21     0.000000\n",
       "22     0.000000\n",
       "23     0.000000\n",
       "24     0.000000\n",
       "25     0.000000\n",
       "26     0.000000\n",
       "27     0.000000\n",
       "28     0.000000\n",
       "29     0.000000\n",
       "...         ...\n",
       "15625  0.000000\n",
       "15626  0.000000\n",
       "15627  0.000000\n",
       "15628  0.000000\n",
       "15629  0.000000\n",
       "15630  0.000000\n",
       "15631  0.000000\n",
       "15632  0.000000\n",
       "15633  0.000000\n",
       "15634  0.000000\n",
       "15635  0.000227\n",
       "15636  0.000151\n",
       "15637  0.000301\n",
       "15638  0.000000\n",
       "15639  0.000000\n",
       "15640  0.000000\n",
       "15641  0.000000\n",
       "15642  0.000000\n",
       "15643  0.000000\n",
       "15644  0.000000\n",
       "15645  0.000000\n",
       "15646  0.000000\n",
       "15647  0.000000\n",
       "15648  0.000000\n",
       "15649  0.000000\n",
       "15650  0.000000\n",
       "15651  0.000000\n",
       "15652  0.000067\n",
       "15653  0.000000\n",
       "15654  0.000000\n",
       "\n",
       "[15655 rows x 1 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rf=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\payal2.bhatia\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rf.fit(X_train, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred=Rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.528125\n"
     ]
    }
   ],
   "source": [
    "# print(metrics.accuracy_score(label_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB=GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NB.fit(X_train.toarray(), label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred=NB.predict(X_test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# print(metrics.accuracy_score(label_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### POS Tags segregation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       affinia/RB chicago/VBZ one/CD worst/NN hotel/N...\n",
       "1       recent/JJ stay/NN affina/RB chicago/JJ hotel/N...\n",
       "2       stay/VB affina/RB chicago/JJ anniversari/JJ ho...\n",
       "3       look/NN high/JJ end/NN hotel/NN magnific/NN mi...\n",
       "4       return/NN long/JJ weekend/NN chicago/NN wife/N...\n",
       "5       wife/NN stay/VB affinia/RB chicago/VBN last/JJ...\n",
       "6       terribl/NN experi/NN stay/VBP wall/RB thin/JJ ...\n",
       "7       stay/VB affnia/JJ hotel/NN chicago/NN extrem/N...\n",
       "8       read/VB good/JJ review/NN affinia/JJ hotel/NN ...\n",
       "9       extremli/NN unhappi/JJ recent/JJ stay/NN affin...\n",
       "10      terribl/NN experi/NN famili/NN affinia/NN chic...\n",
       "11      affinia/NN chicago/RB obvious/JJ cater/NN wed/...\n",
       "12      recent/JJ stay/NN affinia/IN hotel/NN chicago/...\n",
       "13      extrem/NN disappoint/NN stay/VBP hotel/RB look...\n",
       "14      affinia/JJ hotel/NN chicago/VBZ one/CD interes...\n",
       "15      mani/JJ highqual/JJ hotel/NN chicago/NN mani/V...\n",
       "16      trip/NN chicago/NN complet/NN delight/NN despi...\n",
       "17      truli/NNS sort/VBP person/NN write/JJ neg/NN r...\n",
       "18      hello/NN recent/JJ stay/NN affinia/IN hotel/NN...\n",
       "19      hope/NN would/MD pleasant/VB stay/VB turn/JJ n...\n",
       "20      recent/JJ stay/JJ hotel/NN allegro/NN chicago/...\n",
       "21      recent/JJ stay/JJ hotel/NN allegro/NN chicago/...\n",
       "22      recent/JJ visit/NN chicago/VBD stay/JJ hotel/N...\n",
       "23      visit/NN hotel/NN allegro/NN chicago/JJ vacat/...\n",
       "24      unimpress/JJ qualiti/JJ hotel/NN overal/JJ loo...\n",
       "25      hotel/NN allegro/NNS locat/VBP chicago/JJ loop...\n",
       "26      daughter/NN want/VBP spend/JJ weekend/NN chica...\n",
       "27      arriv/JJ hotel/NN minut/NN prior/RB check/NN t...\n",
       "28      stay/VB allegro/JJ two/CD day/NN big/JJ prolem...\n",
       "29      upon/IN arriv/JJ hotel/NN allegro/NN chicago/N...\n",
       "                              ...                        \n",
       "1570    wonder/VB hotel/NN amen/NNS everyon/VBP help/N...\n",
       "1571    third/JJ trip/NN chicago/NN year/NN love/NN ci...\n",
       "1572    stay/NN busi/RB night/NN realli/NNS like/IN at...\n",
       "1573    first/JJ time/NN chicago/NN stay/VB swissotel/...\n",
       "1574    enjoy/DT day/NN weekend/NN swissotel/NN chicag...\n",
       "1575    niec/NNS stay/VBP long/RB weekend/NN wonder/NN...\n",
       "1576    best/JJS servic/JJ staff/NN incred/VBD never/R...\n",
       "1577    love/VB boyfriend/NN book/NN hotel/NN onlin/NN...\n",
       "1578    stay/NN swissotel/VBZ special/JJ birthday/JJ w...\n",
       "1579    recent/JJ stay/JJ hotel/NN famili/NN terrif/NN...\n",
       "1580    quaint/NN romant/NN yet/RB masculin/JJ ive/JJ ...\n",
       "1581    girlfriend/NN stay/NN night/NN talbott/NN retu...\n",
       "1582    wife/NN spent/VBD night/NN talbott/NN room/NN ...\n",
       "1583    pull/VB away/RP taxi/JJ head/NN airport/NN tri...\n",
       "1584    return/NN love/NN shop/NN trip/NN chicago/NN n...\n",
       "1585    love/VB stay/NN talbott/IN chicago/NNS attend/...\n",
       "1586    wife/NN stay/VB two/CD night/NN talbott/NNS en...\n",
       "1587    locat/NN locat/NN locat/VBZ great/JJ find/JJ e...\n",
       "1588    stay/NN great/JJ review/NN true/JJ highli/NN i...\n",
       "1589    stay/NN talbott/NN twice/RB last/JJ week/NN pl...\n",
       "1590    husband/NN stay/NN three/CD night/NN visit/NN ...\n",
       "1591    book/NN anoth/DT hotel/NN block/VB away/RP spe...\n",
       "1592    stay/NN night/NN great/JJ hotel/NN updat/JJ ro...\n",
       "1593    stay/NN talbott/IN week/NN enjoy/VBP stay/NN r...\n",
       "1594    return/NN night/NN stay/NN talbott/IN first/JJ...\n",
       "1595    stay/NN talbott/RB night/NN busi/NN plea/NN st...\n",
       "1596    love/VB talbott/NN locat/NN fabulousveri/VBP c...\n",
       "1597    husband/NN attend/VBP confer/NN chicago/JJ wee...\n",
       "1598    great/JJ find/VBP downtown/JJ chicago/JJ price...\n",
       "1599    chicago/RB one/CD favorit/NN citi/VBZ visit/NN...\n",
       "Name: pos, Length: 1600, dtype: object"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"pos\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Clustering on pos tags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=250, n_iter=25, random_state=12)\n",
    "truncated_tfidf = svd.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280, 250)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncated_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280, 15655)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0018546038510173228"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truncated_tfidf.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
